---
layout: main
---

This is the page of the course *Advanced Topics in Computational Semantics* offered at the [University of Amsterdam][UvA]

Course coordinator: [Ekaterina Shutova](//www.cl.cam.ac.uk/~es407/)

Teaching assistants: [Phillip Lippe](mailto:phillip.lippe@googlemail.com) and [Verna Dankers](mailto:vernadankers@gmail.com)

## Goals

- Learn to apply representation learning methods to natural language data
- Gain experience with natural language processing techniques
- Learn about the state-of-the-art in learning algorithms for representation learning in NLP

## Content

The field of computational semantics is concerned with automatic interpretation of natural language. This course will provide an overview of state-of-the-art statistical approaches to semantics. Specifically, we will look at learning sparse and dense representations of word meaning, modelling predicate-argument structure, compositional semantics and neural models of phrase and sentence meaning. The course will also cover semantic models that lie at the intersection with other fields: multimodal semantic models that draw knowledge from linguistic and visual data, and cognitively-motivated semantic models and their evaluation against brain imaging data. Finally, we will look at the real world applications of these models in areas such as opinion mining and automated fact checking.

This is an advanced research seminar aiming to introduce students to recent developments in the field of NLP. The course will consist of a set of lectures and seminar sessions, where the students will present and discuss recent research papers. This year we will focus on representation learning for NLP, considering different levels of language analysis: words, sentences and longer discourse fragments. We will also look at the recently proposed contextualised word representation models (such as ELMo and BERT) and joint learning methods (including multilingual joint learning and multitask learning).

An important component of the course is a research project, in which the students will have the opportunity to implement a number of semantic models, perform experiments addressing a new research question and write a research paper.

## Assessment

In this setup, the course has no exam. The grade is based on participation, including presentations of literature that the students give (25%) and a series of practical assignments, culminating in a research report that the students submit at the end (75%).

- Presentation and participation: 25%
- Practical 1: Learning general-purpose sentence representations: 25%
- Research project (group work): 50% (10% for the poster presentaion; 40% for the research paper)

## Recommended reading

Since the course focuses on the recent advances in the field of NLP, there is no text book. The students will be referred to research papers throughout the course.

## Recommended prior knowledge

Machine Learning 1 and Natural Language Processing 1

For those of you who have not attended NLP1 please check the [course website](https://cl-illc.github.io/nlp1/) and reading materials.




[UvA]: {{ site.uva_url }} "Universiteit van Amsterdam"
