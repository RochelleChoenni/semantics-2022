-
  layout: lecture
  selected: y
  date: 2021-03-29
  img: introduction-icon_1-267x300
  uid: intro
  title: "Introduction: Learning word and sentence representations"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this introductory lecture I will give an overview of the course and we will discuss learning word and sentence representations from text."
  background:
  discussion:
  slides: resources/slides/Sem2020-lecture1.pdf
  further: 
   -  "Samuel R Bowman, Gabor Angeli, Christopher Potts, and Christopher D Manning. [A large annotated corpus for learning natural language inference](https://arxiv.org/pdf/1508.05326.pdf). arXiv preprint arXiv:1508.05326, 2015."
   - "Alexis Conneau and Douwe Kiela. [Senteval: An evaluation toolkit for universal sentence representations](https://www.aclweb.org/anthology/L18-1269.pdf). In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC-2018), 2018."
   - "Alexis Conneau, Douwe Kiela, Holger Schwenk, Loic Barrault, and Antoine Bordes. [Supervised learning of universal sentence representations from natural language inference data](https://arxiv.org/pdf/1705.02364.pdf). arXiv preprint arXiv:1705.02364, 2017."
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2021-04-06
  img: Sent-rep
  uid: l3
  title: "Seminar: Sentence representations and contextualised word representations"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: "In this session we will discuss two recent papers on learning general-purpose sentence representations and contextualised word representations."
  background:
  discussion: 
    - "In this session we will discuss the following papers:"
    - "Allen Nie, Erin D. Bennett, Noah D. Goodman. 2019. [DisSent: Learning Sentence Representations from Explicit Discourse Relations](https://www.aclweb.org/anthology/P19-1442.pdf). In Proceedings of ACL 2019."
    - "Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee and Luke Zettlemoyer 2018.  [Deep contextualized word representations](https://arxiv.org/pdf/1802.05365.pdf). In Proceedings of NAACL 2018, New Orleans, Louisiana."
  slides: 
  further:
    - "Lajanugen Logeswaran and Honglak Lee. 2018. [An efficient framework for learning sentence representations](https://openreview.net/pdf?id=rJvJXZb0W). In Proceedings of ICLR 2018."
    - "Ge Gao, Eunsol Choi, Yejin Choi and Luke Zettlemoyer. 2018. [Neural Metaphor Detection in Context](https://aclweb.org/anthology/D18-1060). In Proceedings of EMNLP 2018, Brussels, Belgium"
    - "Please see Canvas for project descriptions and references to related papers."
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2021-04-09
  img: bert
  uid: l4
  title: "Attention and transformers"
  instructor: "Phillip Lippe and Ekaterina Shutova"
  note: 
  abstract: "In this session we will introduce attention and transformer architectures"
  background:
  discussion:
  slides: resources/slides/Sem2021-attention-lecture.pdf
  further:
    - "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin. [Attention Is All You Need](https://arxiv.org/abs/1706.03762). In Proceedings of NIPS 2017."
    - "A very helpful [blog post](https://jalammar.github.io/illustrated-transformer/) explaining the transformer architecture."
    - "Visualization of attention heads for BERT: [https://github.com/jessevig/bertviz](https://github.com/jessevig/bertviz)"
  code: 
  data:  
-
  layout: lecture
  selected: y
  date: 2021-04-12
  img: BERT
  uid: l5
  title: "Seminar: The BERT model"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: "In this session we will discuss the BERT model."
  background:
  discussion: 
    - "In this session we will discuss the following papers:" 
    - "Jacob Devlin, Ming-Wei Chang, Kenton Lee and Kristina Toutanova. 2019. [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf). In Proceedings of NAACL 2019."
    - "Ian Tenney, Dipanjan Das, Ellie Pavlick. 2019.  [BERT Rediscovers the Classical NLP Pipeline](https://www.aclweb.org/anthology/P19-1452/). In Proceedings of ACL 2019."
  slides:
  code: 
  data:   
-
  layout: lecture
  selected: y
  date: 2021-04-16
  img: MTL
  uid: l6
  title: "Multitask learning"
  instructor: "Verna Dankers and Ekaterina Shutova"
  note: 
  abstract: "In this session we will introduce the idea of multitask learning and the architectures proposed for it. We will then discuss the language processing tasks that can benefit each other through information sharing."
  background:
  discussion: 
  slides: resources/slides/atcs_lecture_multitask_learning.pdf
  further:
  code: 
  data:   
-
  layout: lecture
  selected: y
  date: 2021-04-19
  img: MTL-NLP
  uid: l7
  title: "Seminar: Multitask learning"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: "In this session we will discuss several recent multitask learning experiments."
  background:
  discussion: 
    - "In this session we will discuss the following papers:"
    - "Hashimoto, K., Tsuruoka, Y., & Socher, R. (2017). [A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks](https://arxiv.org/pdf/1611.01587.pdf). In Proceedings of EMNLP 2017."
    - "Verna Dankers, Marek Rei, Martha Lewis and Ekaterina Shutova (2019). [Modelling the interplay of metaphor and emotion through multitask learning](https://www.aclweb.org/anthology/D19-1227.pdf). In Proceedings of EMNLP 2019."
  slides:
  further:
  code: 
  data:    
-
  layout: lecture
  selected: y
  date: 2021-04-23
  img: Meta-learning
  uid: l9
  title: "Meta-learning"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: "In this session I will introduce the meta-learning framerwork and we will discuss the application of meta-learning to NLP."
  background:
  slides: resources/slides/Sem2021-meta-learning-lecture.pdf
  further:  
    - "The paper by Finn et al (2017) introducing [model-agnostic meta-learning](https://arxiv.org/abs/1703.03400)."
    - "Papers listed in the slides."
  discussion:  
    - "In this session we will discuss the following papers:"
    - "Trapit Bansal, Rishikesh Jha, Andrew McCallum, 2019. [Learning to Few-Shot Learn Across Diverse Natural Language Classification Tasks](https://arxiv.org/pdf/1911.03863.pdf). Arxiv."
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2021-04-30
  img: Multilingual
  uid: l8
  title: "Seminar: Multilingual models"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: "In this session we will discuss learning multilingual word and sentence representations."
  background:
  discussion: 
    - "In this session we will discuss the following papers:"
    - "Mikel Artetxe and Holger Schwenk. 2018. [Massively Multilingual Sentence Embeddings for Zero-Shot Cross-Lingual Transfer and Beyond.](https://arxiv.org/pdf/1812.10464.pdf) Transactions of the Association for Computational Linguistics."
    - "Nooralahzadeh, F., Bekoulis, G., Bjerva, J., & Augenstein, I. (2020). [Zero-Shot Cross-Lingual Transfer with Meta Learning](https://arxiv.org/pdf/2003.02739.pdf). arXiv preprint arXiv:2003.02739."
  slides: 
  code: 
  data:  
-
  layout: lecture
  selected: y
  date: 2021-05-10
  img: GNN
  uid: l11
  title: "Seminar: Model interpretation and subnetworks"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: "In this session we will discuss recent techniques for model interpretation in NLP, such as measuring the importance of individual attention heads and finding task-specific subnetworks in the BERT model."
  background:
  discussion: 
    - "In this session we will discuss the following papers:"
    - "Paul Michel, Omer Levy, Graham Neubig. [Are Sixteen Heads Really Better than One?](https://proceedings.neurips.cc/paper/2019/file/2c601ad9d2ff9bc8b282670cdd54f69f-Paper.pdf) In Proceedings of NeuroIPS 2019."
    - "Tianlong Chen, Jonathan Frankle, Shiyu Chang, Sijia Liu, Yang Zhang, Zhangyang Wang, Michael Carbin. [The Lottery Ticket Hypothesis for Pre-trained BERT Networks.](https://proceedings.neurips.cc/paper/2020/file/b6af2c9703f203a2794be03d443af2e3-Paper.pdf) In Proceedings of NeuroIPS 2020."
  slides: 
  further:
-
  layout: lecture
  selected: y
  date: 2021-05-17
  img: Discourse
  uid: l10
  title: "Seminar: Document representations and graph neural networks"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: "In this session we will discuss learning representations of discourse fragments and documents, and modelling discourse structure via rhetorical relations. In the second half of the class, we will discuss the applications of graph neural networks in NLP."
  background:
  discussion: 
    - "In this session we will discuss the following papers:"
    - "Yangfeng Ji and Noah A. Smith. 2017. [Neural Discourse Structure for Text Categorization](https://www.aclweb.org/anthology/P17-1092). In Proceedings of ACL 2017."
  slides: 
  further: 
  code: 
  data:  
-
  layout: lecture
  selected: y
  date: 2021-05-21
  img: Poster
  uid: l12
  title: "Project presentations"
  instructor: "Ekaterina Shutova, Rochelle Choenni and Phillip Lippe"
  note: 
  abstract: "In this session, you will present the results of your research projects."
  background:
  discussion:
  slides: 
  code: 
  data: 
