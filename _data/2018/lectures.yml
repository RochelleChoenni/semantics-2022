-
  layout: lecture
  selected: y
  date: 2018-04-03
  img: introduction-icon_1-267x300
  uid: intro
  title: "Introduction"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this introductory lecture we will discuss the distributional models for learning word representations from text."
  background:
  discussion:
  slides: resources/slides/slides1-ull.pdf
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-04-04
  img: skip-gram
  uid: intro
  title: "Semantics with dense vectors and compositional semantics"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture we will discuss the skip-gram model and its properties, and then move on to compositional semantics, concerned with modelling phrase meaning."
  background:
  discussion:
  slides: resources/slides/slides2-ull.pdf
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-04-10
  img: skip-gram
  uid: intro
  title: "Student presentations: Dependency-based embeddings, specialisation and retro-fitting"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture we will discuss the following papers:"
    - "Omer Levy and Yoav Goldberg. 2014. Dependency-based word embeddings. In proceedings of ACL 2014. https://levyomer.files.wordpress.com/2014/04/dependency-based-word-embeddings-acl-2014.pdf"
  background:
  discussion:
  slides: 
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-04-11
  img: skip-gram
  uid: intro
  title: "Student presentations: Multilingual embeddings and compositional semantics"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    ""
  background:
  discussion:
  slides: 
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-04-17
  img: dgm
  uid: dgm
  title: "Probabilistic modelling for NLP powered by deep learning"
  instructor: Wilker Aziz
  abstract:  "In this lecture I will present probabilistic modelling with neural networks, we will start with maximum likelihood estimation based on fully observed data, then we will discuss the challenges of learning distributions over observed and unobserved (latent) data. We will then talk about variational inference and how it may help us estimate deep generative models."
  background:
    - "[The wake-sleep algorithm for unsupervised neural networks](http://www.cs.toronto.edu/~fritz/absps/ws.pdf)"
    - "[Neural Variational Inference and Learning in Belief Networks](https://arxiv.org/pdf/1402.0030.pdf)"
    - "Variational Inference: "
    - "Chapter 2 of Matthew Beal's [PhD thesis](http://www.cse.buffalo.edu/faculty/mbeal/papers/beal03.pdf) gives a very clear development of variational inference for Bayesian models."
    - "An outstanding account of variational methods with lots of references to recent developments is given in David Blei's [tutorial](https://arxiv.org/pdf/1601.00670.pdf)."
  further:
    - "Stochastic optimisation:"
    - "Practical notes by [Leon Bottou](http://cilvr.cs.nyu.edu/diglib/lsml/bottou-sgd-tricks-2012.pdf) (in particular section 5.2 discusses learning rate schedules)"
    - "A [handbook chapter](http://www.jhuapl.edu/spsa/PDF-SPSA/Handbook04_StochasticOptimization.pdf)"
    - "The [original](https://www.jstor.org/stable/2236626) `advanced!`"
  slides: resources/slides/dgm.pdf
-
  layout: lecture
  selected: y
  date: 2018-04-18
  img: vae
  uid: vae
  title: "Variational auto-encoders"
  instructor: Wilker Aziz
  abstract:  "In this lecture I will present generative modelling with neural networks, we will start with a mixture model and then present the variational auto-encoder."
  background:
    - "The [wake-sleep algorithm](http://www.cs.toronto.edu/~fritz/absps/ws.pdf)"
    - 
    - "Variational Inference: "
    - "Chapter 2 of Matthew Beal's [PhD thesis](http://www.cse.buffalo.edu/faculty/mbeal/papers/beal03.pdf) gives a very clear development of variational inference for Bayesian models."
    - "An outstanding account of variational methods with lots of references to recent developments is given in David Blei's [tutorial](https://arxiv.org/pdf/1601.00670.pdf)."
    - "[Gaussian distribution](https://en.wikipedia.org/wiki/Normal_distribution)"
    - "The original: [Kingma and Welling (2014)](https://arxiv.org/abs/1312.6114) and [Rezend et al (2014)](https://arxiv.org/abs/1401.4082)"
  further:
    - "Variational auto-encoders:"
    - "A [tutorial](https://arxiv.org/abs/1606.05908) (`disclaimer:` not my favourite!)"
    - "More on reparameterisation (`advanced!`): [Titsias and Lazaro-Gredilla (2014)](http://www2.aueb.gr/users/mtitsias/papers/titsias14.pdf) and [Ruiz et al (2016)](https://arxiv.org/abs/1610.02287)"
    - "KL for Gaussians: [Soch and Allefeld (2016)](https://arxiv.org/pdf/1611.01437.pdf) or [wikipedia](https://en.wikipedia.org/wiki/Kullbackâ€“Leibler_divergence#Kullback.E2.80.93Leibler_divergence_for_multivariate_normal_distributions)"
    - "Stochastic optimisation:"
    - "Practical notes by [Leon Bottou](http://cilvr.cs.nyu.edu/diglib/lsml/bottou-sgd-tricks-2012.pdf) (in particular section 5.2 discusses learning rate schedules)"
    - "A [handbook chapter](http://www.jhuapl.edu/spsa/PDF-SPSA/Handbook04_StochasticOptimization.pdf)"
    - "The [original](https://www.jstor.org/stable/2236626) `advanced!`"
  slides: resources/slides/vae.pdf
