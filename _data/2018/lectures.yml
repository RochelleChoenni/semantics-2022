-
  layout: lecture
  selected: y
  date: 2018-04-03
  img: introduction-icon_1-267x300
  uid: intro
  title: "Introduction"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this introductory lecture we will discuss the distributional models for learning word representations from text."
  background:
  discussion:
  slides: resources/slides/slides1-ull.pdf
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-04-04
  img: skip-gram
  uid: l2
  title: "Semantics with dense vectors and compositional semantics"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture we will discuss the skip-gram model and its properties, and then move on to compositional semantics, concerned with modelling phrase meaning."
  background:
  discussion:
  slides: resources/slides/slides2-ull.pdf
  further: 
    - "The following paper provides a nice explanation of skip-gram with negative sampling:"
    - "Yoav Goldberg and Omer Levy. [word2vec Explained: Deriving Mikolov et al.’s Negative-Sampling Word-Embedding Method](https://arxiv.org/pdf/1402.3722.pdf)"
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-04-10
  img: retrofitting
  uid: l3
  title: "Student presentations: Dependency-based word embeddings, specialisation and retro-fitting"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: "In this session we will discuss three recent papers on dependency-based word embeddings, specialisation and retro-fitting."
  background:
  discussion: 
    - "In this session we will discuss the following papers:"
    - "Omer Levy and Yoav Goldberg. 2014. [Dependency-based word embeddings](https://levyomer.files.wordpress.com/2014/04/dependency-based-word-embeddings-acl-2014.pdf). In proceedings of ACL 2014."
    - "Manaal Faruqui, Jesse Dodge, Sujay K. Jauhar, Chris Dyer, Eduard Hovy and Noah A. Smith. 2015. [Retrofitting Word Vectors to Semantic Lexicons](https://www.cs.cmu.edu/~hovy/papers/15HLT-retrofitting-word-vectors.pdf). In Proceedings of NAACL 2015."
    - "Douwe Kiela, Felix Hill and Stephen Clark. 2015. [Specializing Word Embeddings for Similarity or Relatedness](http://www.cl.cam.ac.uk/~dk427/papers/emnlp2015c.pdf). In Proceedings of EMNLP 2015."
  slides: 
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-04-11
  img: Multilingual
  uid: l4
  title: "Student presentations: Multilingual embeddings and compositional semantics"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this session we will discuss learning multilingual word representations and representations for phrases and sentences."
  background:
  discussion: 
    - "In this session we will discuss the following papers:"
    - "Jocelyn Coulmance, Jean-Marc Marty, Guillaume Wenzek and Amine Benhalloum. 2015. [Trans-gram, Fast Cross-lingual Word-embeddings](http://www.aclweb.org/anthology/D15-1131). In Proceedings of EMNLP 2015."
    - "Karl Moritz Hermann and Phil Blunsom. 2014. [Multilingual Models for Compositional Distributed Semantics](http://www.aclweb.org/anthology/P/P14/P14-1006.pdf). In Proceedings of ACL 2014."
    - "Richard Socher, Brody Huval, Christopher D. Manning and Andrew Y. Ng. 2012. [Semantic Compositionality through Recursive Matrix-Vector Spaces](http://ai.stanford.edu/~ang/papers/emnlp12-SemanticCompositionalityRecursiveMatrixVectorSpaces.pdf). In Proceedings of EMNLP 2012."
  slides: 
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-04-17
  img: dgm
  uid: dgm
  title: "Probabilistic modelling for NLP powered by deep learning"
  instructor: Wilker Aziz
  abstract:  "In this lecture I will present probabilistic modelling with neural networks, we will start with maximum likelihood estimation based on fully observed data, then we will discuss the challenges of learning distributions over observed and unobserved (latent) data. We will then talk about variational inference and how it may help us estimate deep generative models."
  background:
    - "[The wake-sleep algorithm for unsupervised neural networks](http://www.cs.toronto.edu/~fritz/absps/ws.pdf)"
    - "[Neural Variational Inference and Learning in Belief Networks](https://arxiv.org/pdf/1402.0030.pdf)"
    - "Variational Inference: "
    - "Chapter 2 of Matthew Beal's [PhD thesis](http://www.cse.buffalo.edu/faculty/mbeal/papers/beal03.pdf) gives a very clear development of variational inference for Bayesian models."
    - "An outstanding account of variational methods with lots of references to recent developments is given in David Blei's [tutorial](https://arxiv.org/pdf/1601.00670.pdf)."
  further:
    - "Stochastic optimisation:"
    - "Practical notes by [Leon Bottou](http://cilvr.cs.nyu.edu/diglib/lsml/bottou-sgd-tricks-2012.pdf) (in particular section 5.2 discusses learning rate schedules)"
    - "A [handbook chapter](http://www.jhuapl.edu/spsa/PDF-SPSA/Handbook04_StochasticOptimization.pdf)"
    - "The [original](https://www.jstor.org/stable/2236626) `advanced!`"
  slides: resources/slides/dgm.pdf
-
  layout: lecture
  selected: y
  date: 2018-04-18
  img: vae
  uid: vae
  title: "Variational auto-encoders"
  instructor: Wilker Aziz
  abstract:  "In this lecture I will present the variational auto-encoder, an important deep generative model that makes a building block for many others. We will also learn about the reparameterised gradient, a major development for efficient estimation of DGMs."
  background:
    - "[Gaussian distribution](https://en.wikipedia.org/wiki/Normal_distribution)"
    - "The original: [Kingma and Welling (2014)](https://arxiv.org/abs/1312.6114) and [Rezend et al (2014)](https://arxiv.org/abs/1401.4082)"
  further:
    - "Variational auto-encoders:"
    - "A [tutorial](https://arxiv.org/abs/1606.05908) (`disclaimer:` not my favourite!)"
    - "More on reparameterisation (`advanced!`): [Titsias and Lazaro-Gredilla (2014)](http://www2.aueb.gr/users/mtitsias/papers/titsias14.pdf) and [Ruiz et al (2016)](https://arxiv.org/abs/1610.02287)"
    - "[Automatic Differentiation Variational Inference](https://arxiv.org/pdf/1603.00788.pdf)"
  slides: resources/slides/dgm.pdf
-
  layout: lecture
  selected: y
  date: 2018-04-24
  img: embedalign
  uid: worddgms
  title: "Generative models of word representation"
  instructor: Wilker Aziz
  abstract:  "In this lecture I will present two deep latent variable models of word representation: a discriminative and a generative one."
  background:
    - "CBOW and Skip-gram: [Distributed Representations of Words and Phrases and their Compositionality](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)"
    - "Skip-gram is a binary classifier: [word2vec Explained: Deriving Mikolov et al.’s Negative-Sampling Word-Embedding Method](https://arxiv.org/pdf/1402.3722.pdf)"
    - "Generative modelling via lexical alignment: [Learning Bilingual Word Representations by Marginalizing Alignments](http://acl2014.org/acl2014/P14-2/pdf/P14-2037.pdf)"
  further:
    - "[Embedding Words as Distributions with a Bayesian Skip-gram Model](https://arxiv.org/pdf/1711.11027)"
    - "[Deep Generative Model for Joint Alignment and Word Representation](https://arxiv.org/pdf/1802.05883.pdf)"
  discussion:
    - "[Auto-encoding variational inference for topic models](https://arxiv.org/pdf/1703.01488.pdf)"
    - "[Semantic Parsing with Semi-Supervised Sequential Autoencoders](https://arxiv.org/pdf/1609.09315.pdf)"
  slides: resources/slides/dgm-word.pdf
-
  layout: lecture
  selected: y
  date: 2018-04-25
  img: sntdgms
  uid: sntdgms
  title: "Generative language models"
  instructor: Wilker Aziz
  abstract:  "In this lecture I will present generative models over natural language sentences."
  background:
    - "[Recurrent neural network based language model](http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf)"
  discussion: 
    - "[Generating Sentences from a Continuous Space](https://arxiv.org/pdf/1511.06349.pdf)"
    - "[Variational neural machine translation](https://arxiv.org/pdf/1605.07869.pdf)"
-
  layout: lecture
  selected: y
  date: 2018-05-01
  img: Mitchell-et-al
  uid: may1
  title: "Word representations and neurocognition of language"
  instructor: "Samira Abnar and Ekaterina Shutova"
  note: 
  abstract: "In this session we will give an introductory lecture on the relationship of representation learning and neurocognition of language, and discuss two recent papers on the topic."
  background:
  discussion: 
    - "In this session we will discuss the following papers:"
    - "Tom M Mitchell, Svetlana V Shinkareva, Andrew Carlson, Kai-Min Chang, Vicente L Malave, Robert A Mason, and Marcel Adam Just. 2008. [Predicting human brain activity associated with the meanings of nouns.](https://www.cs.cmu.edu/~tom/pubs/science2008.pdf) Science, 320(5880):1191–1195."
    - "Samira Abnar, Rasyan Ahmed, Max Mijnheer, Willem Zuidema. 2018. [Experiential, Distributional and Dependency-based Word Embeddings have Complementary Roles in Decoding Brain Activity.](http://aclweb.org/anthology/W18-0107) Proceedings Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2018)."
  slides: resources/slides/Word%20Representations%20%20%26%20%20Neurocognition%20of%20Language.pdf
  further:
    - "[From distributional semantics to feature norms: grounding semantic models in human perceptual data](http://aclweb.org/anthology/W15-0107)"
    - "[A Continuous Semantic Space Describes the Representation of Thousands of Object and Action Categories across the Human Brain](https://www.cell.com/neuron/fulltext/S0896-6273(12)00934-8)"
    - "[Natural speech reveals the semantic maps that tile human cerebral cortex](https://www.nature.com/articles/nature17637)"
    - "(http://gallantlab.org/huth2016/)" 
-
  layout: lecture
  selected: y
  date: 2018-05-02
  img: Bonsack_machine
  uid: may2
  title: "Word representations and modelling ambiguity: A case study of metaphor"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: "In this session I will give an introductory lecture on lexical ambiguity and metaphor, and how these phenomena can be modelled using semantic representations. We will then discuss two recent papers on the topic."
  background:
  discussion: 
    - "In this session we will discuss the following papers:"
    - "Dario Gutierrez, Ekaterina Shutova, Tyler Marghetis and Benjamin Bergen. 2016. [Literal and Metaphorical Senses in Compositional Distributional Semantic Models.](http://www.cl.cam.ac.uk/~es407/papers/ACL2016Dario.pdf) In Proceedings of ACL 2016, Berlin, Germany."
    - "Marek Rei, Luana Bulat, Douwe Kiela and Ekaterina Shutova. 2017. [Grasping the Finer Point: A Supervised Similarity Network for Metaphor Detection.](http://www.cl.cam.ac.uk/~es407/papers/emnlp2017marek.pdf) In Proceedings of EMNLP 2017, Copenhagen, Denmark."
  slides: resources/slides/ULL-metaphor.pdf
  further: "Ekaterina Shutova. 2015. [Design and Evaluation of Metaphor Processing Systems](http://www.cl.cam.ac.uk/~es407/papers/EvalPaper.pdf). Computational Linguistics, 41(4): 579-623."
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-05-08
  img: ImageConvNet
  uid: may8
  title: "Multimodal semantics and dialogue"
  instructor: "Elia Bruni and Ekaterina Shutova"
  note: 
  abstract: "In this session we will give an introductory lecture on multimodal semantics, i.e. learning semantic representations from both linguistic and visual data. We will then discuss their application in multimodal dialogue systems."
  background:
  discussion: 
    - "In this session we will discuss the following papers:"
    - "Douwe Kiela and Leon Bottou 2014. [Learning Image Embeddings using Convolutional Neural Networks for Improved Multi-Modal Semantics](http://www.cl.cam.ac.uk/~dk427/papers/emnlp2014.pdf). In Proceedings of EMNLP 2014, Doha, Qatar."
    - "Angeliki Lazaridou, Nghia The Pham, Marco Baroni. 2015. [Combining Language and Vision with a Multimodal Skip-gram Model](http://www.aclweb.org/anthology/N15-1016). In Proceedings of NAACL 2015."
  slides: 
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-05-09
  img: ImageConvNet
  uid: may9
  title: "Multimodal semantics (continued) and introducing the third practical"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: "In this session we will continue our discussion of multimodal semantics. At the end, I will give you an overview of the third practical and what we expect to see in your final report."
  background:
  discussion: 
    - "In this session we will discuss the following papers:"
    - "A.J. Anderson, D. Kiela, S. Clark and M. Poesio. [Visually Grounded and Textual Semantic Models Differentially Decode Brain Activity Associated with Concrete and Abstract Nouns](https://www.transacl.org/ojs/index.php/tacl/article/view/879). Transactions of the Association for Computational Linguistics (TACL)."
    - "Luana Bulat, Stephen Clark and Ekaterina Shutova. 2017. [Speaking, Seeing, Understanding: Correlating semantics models with conceptual representation in the brain](http://www.cl.cam.ac.uk/~es407/papers/emnlp2017luana.pdf). In Proceedings of EMNLP 2017, Copenhagen, Denmark."
    - "Alexis Conneau and Douwe Kiela. [SentEval: An Evaluation Toolkit for Universal Sentence Representations](https://arxiv.org/pdf/1803.05449.pdf)."
  slides: 
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-05-15
  img: graphdgms
  uid: graphdgms
  title: "Latent graph models"
  instructor: Wilker Aziz
  abstract:  "In this lecture I will present models of graph induction."
  background:
    - "[Encoding Sentences with Graph Convolutional Networks for Semantic Role Labeling](http://www.aclweb.org/anthology/D17-1159)"
    - "[The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables](https://arxiv.org/pdf/1611.00712.pdf)"
    - "[Categorical Reparameterization with Gumbel-Softmax](https://arxiv.org/pdf/1611.01144.pdf)"
  discussion:
    - "[Structured Attention Networks](https://arxiv.org/pdf/1702.00887.pdf)"
    - "[Learning to Compose Task-Specific Tree Structures](https://arxiv.org/pdf/1707.02786.pdf)"
  further:
    - "[Learning Structured Text Representations](https://arxiv.org/pdf/1705.09207.pdf)"
    - "[Neural Machine Translation with Source-Side Latent Graph Parsing](https://arxiv.org/pdf/1702.02265.pdf)"
-
  layout: lecture
  selected: y
  date: 2018-05-16
  img: discretedgms
  uid: discretedgms
  title: "Discrete latent variable models"
  instructor: Wilker Aziz
  abstract:  "In this lecture I will present models of whose latent variables are discrete and cannot be exactly marginalised."
  background:
    - "VI without reparameterised gradients: [Neural Variational Inference and Learning in Belief Networks](https://arxiv.org/pdf/1402.0030.pdf)"
    - "Control variates: [MuProp: Unbiased Backpropagation for Stochastic Neural Networks](https://arxiv.org/pdf/1511.05176.pdf)"
  discussion:
    - "[Jointly Learning Sentence Embeddings and Syntax with Unsupervised Tree-LSTMs](https://arxiv.org/pdf/1705.09189.pdf)"
    - "[Learning to Compose Words into Sentences with Reinforcement Learning](https://arxiv.org/pdf/1611.09100.pdf)"
  further:
    - "Investigation of induced latent variables: [Do latent tree learning models identify meaningful structure in sentences?](https://arxiv.org/pdf/1709.01121.pdf)"
    - "No latent variables, but generative training: [Recurrent Neural Network Grammars](https://arxiv.org/pdf/1602.07776.pdf)"
    - "More on gradient estimation: [Simple Statistical Gradient-Flowing Algorithms for Connectionist Reinforcement Learning](https://link.springer.com/content/pdf/10.1007%2FBF00992696.pdf)"
-
  layout: lecture
  selected: y
  date: 2018-05-22
  img: brain
  uid: logicalinf
  title: "Deep learning and logical inference"
  instructor: Jelle Zuidema
  abstract:  "In this guest lecture, Dr Jelle Zuidema will talk about his work on deep learning and logical inference."
-
  layout: lecture
  selected: y
  img: end 
  uid: end
  title: "The End"
  instructor: Ekaterina Shutova and Wilker Aziz
  abstract:  "Here we list topics and papers that you can use to drive your studies beyond what we presented in this course."
  further:
    - "**Deep generative models**"
    - "Beyond Gaussians: [Automatic Differentiation Variational Inference](https://arxiv.org/pdf/1603.00788.pdf)"
    - "Beyond known densities: [Variational Inference with Normalizing Flows](https://arxiv.org/pdf/1505.05770.pdf) and [Improved Variational Inference with Inverse Autoregressive Flow](https://arxiv.org/pdf/1606.04934.pdf)"
    - "Advanced control variates: [Backpropagation through the Void: Optimizing control variates for black-box gradient estimation](https://arxiv.org/pdf/1711.00123.pdf)"
    - "Non-parametric priors: [Nonparametric Variational Auto-encoders for Hierarchical Representation Learning](https://arxiv.org/pdf/1703.07027.pdf)"
    - "Implicit likelihoods: [Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661.pdf) and [Hierarchical Implicit Models and Likelihood-Free Variational Inference](https://arxiv.org/pdf/1702.08896.pdf)"

