-
  layout: lecture
  selected: y
  date: 2018-04-03
  img: introduction-icon_1-267x300
  uid: intro
  title: "Introduction"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this introductory lecture we will discuss the distributional models for learning word representations from text."
  background:
  discussion:
  slides: resources/slides/slides1-ull.pdf
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-04-04
  img: skip-gram
  uid: l2
  title: "Semantics with dense vectors and compositional semantics"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this lecture we will discuss the skip-gram model and its properties, and then move on to compositional semantics, concerned with modelling phrase meaning."
  background:
  discussion:
  slides: resources/slides/slides2-ull.pdf
  further: 
    - "The following paper provides a nice explanation of skip-gram with negative sampling:"
    - "Yoav Goldberg and Omer Levy. [word2vec Explained: Deriving Mikolov et al.’s Negative-Sampling Word-Embedding Method](https://arxiv.org/pdf/1402.3722.pdf)"
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-04-10
  img: retrofitting
  uid: l3
  title: "Student presentations: Dependency-based word embeddings, specialisation and retro-fitting"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: "In this session we will discuss three recent papers on dependency-based word embeddings, specialisation and retro-fitting."
  background:
  discussion: 
    - "In this session we will discuss the following papers:"
    - "Omer Levy and Yoav Goldberg. 2014. [Dependency-based word embeddings](https://levyomer.files.wordpress.com/2014/04/dependency-based-word-embeddings-acl-2014.pdf). In proceedings of ACL 2014."
    - "Manaal Faruqui, Jesse Dodge, Sujay K. Jauhar, Chris Dyer, Eduard Hovy and Noah A. Smith. 2015. [Retrofitting Word Vectors to Semantic Lexicons](https://www.cs.cmu.edu/~hovy/papers/15HLT-retrofitting-word-vectors.pdf). In Proceedings of NAACL 2015."
    - "Douwe Kiela, Felix Hill and Stephen Clark. 2015. [Specializing Word Embeddings for Similarity or Relatedness](http://www.cl.cam.ac.uk/~dk427/papers/emnlp2015c.pdf). In Proceedings of EMNLP 2015."
  slides: 
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-04-11
  img: Multilingual
  uid: l4
  title: "Student presentations: Multilingual embeddings and compositional semantics"
  instructor: "Ekaterina Shutova"
  note: 
  abstract: >
    "In this session we will discuss learning multilingual word representations and representations for phrases and sentences."
  background:
  discussion: 
    - "In this session we will discuss the following papers:"
    - "Jocelyn Coulmance, Jean-Marc Marty, Guillaume Wenzek and Amine Benhalloum. 2015. [Trans-gram, Fast Cross-lingual Word-embeddings](http://www.aclweb.org/anthology/D15-1131). In Proceedings of EMNLP 2015."
    - "Karl Moritz Hermann and Phil Blunsom. 2014. [Multilingual Models for Compositional Distributed Semantics](http://www.aclweb.org/anthology/P/P14/P14-1006.pdf). In Proceedings of ACL 2014."
    - "Richard Socher, Brody Huval, Christopher D. Manning and Andrew Y. Ng. 2012. [Semantic Compositionality through Recursive Matrix-Vector Spaces](http://ai.stanford.edu/~ang/papers/emnlp12-SemanticCompositionalityRecursiveMatrixVectorSpaces.pdf). In Proceedings of EMNLP 2012."
  slides: 
  code: 
  data: 
-
  layout: lecture
  selected: y
  date: 2018-04-17
  img: dgm
  uid: dgm
  title: "Probabilistic modelling for NLP powered by deep learning"
  instructor: Wilker Aziz
  abstract:  "In this lecture I will present probabilistic modelling with neural networks, we will start with maximum likelihood estimation based on fully observed data, then we will discuss the challenges of learning distributions over observed and unobserved (latent) data. We will then talk about variational inference and how it may help us estimate deep generative models."
  background:
    - "[The wake-sleep algorithm for unsupervised neural networks](http://www.cs.toronto.edu/~fritz/absps/ws.pdf)"
    - "[Neural Variational Inference and Learning in Belief Networks](https://arxiv.org/pdf/1402.0030.pdf)"
    - "Variational Inference: "
    - "Chapter 2 of Matthew Beal's [PhD thesis](http://www.cse.buffalo.edu/faculty/mbeal/papers/beal03.pdf) gives a very clear development of variational inference for Bayesian models."
    - "An outstanding account of variational methods with lots of references to recent developments is given in David Blei's [tutorial](https://arxiv.org/pdf/1601.00670.pdf)."
  further:
    - "Stochastic optimisation:"
    - "Practical notes by [Leon Bottou](http://cilvr.cs.nyu.edu/diglib/lsml/bottou-sgd-tricks-2012.pdf) (in particular section 5.2 discusses learning rate schedules)"
    - "A [handbook chapter](http://www.jhuapl.edu/spsa/PDF-SPSA/Handbook04_StochasticOptimization.pdf)"
    - "The [original](https://www.jstor.org/stable/2236626) `advanced!`"
  slides: resources/slides/dgm.pdf
-
  layout: lecture
  selected: y
  date: 2018-04-18
  img: vae
  uid: vae
  title: "Variational auto-encoders"
  instructor: Wilker Aziz
  abstract:  "In this lecture I will present the variational auto-encoder, an important deep generative model that makes a building block for many others. We will also learn about the reparameterised gradient, a major development for efficient estimation of DGMs."
  background:
    - "[Gaussian distribution](https://en.wikipedia.org/wiki/Normal_distribution)"
    - "The original: [Kingma and Welling (2014)](https://arxiv.org/abs/1312.6114) and [Rezend et al (2014)](https://arxiv.org/abs/1401.4082)"
  further:
    - "Variational auto-encoders:"
    - "A [tutorial](https://arxiv.org/abs/1606.05908) (`disclaimer:` not my favourite!)"
    - "More on reparameterisation (`advanced!`): [Titsias and Lazaro-Gredilla (2014)](http://www2.aueb.gr/users/mtitsias/papers/titsias14.pdf) and [Ruiz et al (2016)](https://arxiv.org/abs/1610.02287)"
    - "[Automatic Differentiation Variational Inference](https://arxiv.org/pdf/1603.00788.pdf)"
  slides: resources/slides/dgm.pdf
-
  layout: lecture
  selected: y
  date: 2018-04-24
  img: embedalign
  uid: worddgms
  title: "Generative models of word representation"
  instructor: Wilker Aziz
  abstract:  "In this lecture I will present two models of word representation: a discriminative and a generative one."
  background:
    - "[Distributed Representations of Words and Phrases and their Compositionality](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)"
    - "[Learning Bilingual Word Representations by Marginalizing Alignments](http://acl2014.org/acl2014/P14-2/pdf/P14-2037.pdf)"
  further:
    - "[Embedding Words as Distributions with a Bayesian Skip-gram Model](https://arxiv.org/pdf/1711.11027)"
    - "[Deep Generative Model for Joint Alignment and Word Representation](https://arxiv.org/pdf/1802.05883.pdf)"
  discussion:
    - "[Auto-encoding variational inference for topic models](https://arxiv.org/pdf/1703.01488.pdf)"
    - "[Semantic Parsing with Semi-Supervised Sequential Autoencoders](https://arxiv.org/pdf/1609.09315.pdf)"
-
  layout: lecture
  selected: y
  date: 2018-04-25
  img: sntdgms
  uid: sntdgms
  title: "Generative language models"
  instructor: Wilker Aziz
  abstract:  "In this lecture I will present generative models over natural language sentences."
  background:
    - "[Recurrent neural network based language model](http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf)"
  discussion: 
    - "[Generating Sentences from a Continuous Space](https://arxiv.org/pdf/1511.06349.pdf)"
    - "[Variational neural machine translation](https://arxiv.org/pdf/1605.07869.pdf)"
-
  layout: lecture
  selected: y
  date: 2018-05-01
  img: Mitchell-et-al
  uid: may1
  title: "Word representations and neurocognition of language"
  instructor: "Samira Abnar and Ekaterina Shutova"
  note: 
  abstract: "In this session we will give an introductory lecture on the relationship of representation learning and neurocognition of language, and discuss two recent papers on the topic."
  background:
  discussion: 
    - "In this session we will discuss the following papers:"
    - "Tom M Mitchell, Svetlana V Shinkareva, Andrew Carlson, Kai-Min Chang, Vicente L Malave, Robert A Mason, and Marcel Adam Just. 2008. [Predicting human brain activity associated with the meanings of nouns.](https://www.cs.cmu.edu/~tom/pubs/science2008.pdf) Science, 320(5880):1191–1195."
    - "Samira Abnar, Rasyan Ahmed, Max Mijnheer, Willem Zuidema. 2018. [Experiential, Distributional and Dependency-based Word Embeddings have Complementary Roles in Decoding Brain Activity.](http://aclweb.org/anthology/W18-0107) Proceedings Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2018)."
  slides: 
  code: 
  data: 
